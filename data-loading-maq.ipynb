{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bad16a",
   "metadata": {},
   "source": [
    "# Data loading \n",
    "\n",
    "Here we will be using the ```.csv``` file we downloaded from MAQ and do the following:\n",
    " - Check metadata and table datatypes of the csv file/table\n",
    " - Convert the csv file to pandas dataframe and check the datatypes. Additionally check the data dictionary to make sure you have the right datatypes in pandas, as pandas will automatically create the table in our database.\n",
    " - Generate the DDL CREATE statement from pandas for a sanity check.\n",
    " - Create a connection to our database using SQLAlchemy\n",
    " - Convert our huge paraquet file into a iterable that has batches of 100,000 rows and load it into our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2170213b-6b89-4e81-b215-d1a7272943e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:55:14.141738Z",
     "start_time": "2023-12-03T23:55:14.124217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from time import time\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c9bf423-fb4e-4edc-a28e-790446dea94e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_file = \"data/Amsterdam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43f6ea7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:28:22.870376Z",
     "start_time": "2023-12-03T23:28:22.563414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42980 entries, 0 to 42979\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Timestamp     42980 non-null  object\n",
      " 1   Qs_in_Avg     42980 non-null  object\n",
      " 2   T1_Avg        42980 non-null  object\n",
      " 3   air_pressure  1383 non-null   object\n",
      " 4   RH            969 non-null    object\n",
      " 5   wind_speed    1383 non-null   object\n",
      " 6   wind_dir      1383 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert to pandas and check data \n",
    "df = pd.read_csv(data_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "795c3374-a4cf-4d36-aa5c-061942587a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drops= [\"air_pressure\", \"RH\", \"wind_speed\", \"wind_dir\"]\n",
    "df = df.drop(columns = drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaeb52aa-7e0d-4c7b-a1a6-27af05a37c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Qs_in_Avg</th>\n",
       "      <th>T1_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-01 03:41:00</td>\n",
       "      <td>-3.055</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-01 03:42:00</td>\n",
       "      <td>-2.959</td>\n",
       "      <td>8.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-01 03:43:00</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-01 03:44:00</td>\n",
       "      <td>-2.884</td>\n",
       "      <td>8.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-04-01 03:45:00</td>\n",
       "      <td>-2.894</td>\n",
       "      <td>8.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp Qs_in_Avg T1_Avg\n",
       "1  2024-04-01 03:41:00    -3.055    8.4\n",
       "2  2024-04-01 03:42:00    -2.959   8.39\n",
       "3  2024-04-01 03:43:00    -3.439   8.38\n",
       "4  2024-04-01 03:44:00    -2.884   8.37\n",
       "5  2024-04-01 03:45:00    -2.894   8.37"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[1:,]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cde7fe6-2926-4a91-b7a9-670d6af0c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.astype({'Qs_in_Avg': 'float'})\n",
    "df = df.astype({'T1_Avg': 'float'})\n",
    "\n",
    "# df = df.astype({'Qs_in_Avg': 'float'}), 'T1_Avg': 'float'}).dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf039a0",
   "metadata": {},
   "source": [
    "We need to first create the connection to our postgres database. We can feed the connection information to generate the CREATE SQL query for the specific server. SQLAlchemy supports a variety of servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06ad5991-80be-46f9-a506-a1497147dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42979 entries, 1 to 42979\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Timestamp  42979 non-null  datetime64[ns]\n",
      " 1   Qs_in_Avg  42979 non-null  float64       \n",
      " 2   T1_Avg     42979 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2)\n",
      "memory usage: 1007.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44e701ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:50:25.811951Z",
     "start_time": "2023-12-03T22:50:25.393987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x120de7f10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an open SQL database connection object or a SQLAlchemy connectable\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/maq_weather')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c96a1075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:50:43.628727Z",
     "start_time": "2023-12-03T22:50:43.442337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE \"Amsterdam_april_data\" (\n",
      "\t\"Timestamp\" TIMESTAMP WITHOUT TIME ZONE, \n",
      "\t\"Qs_in_Avg\" FLOAT(53), \n",
      "\t\"T1_Avg\" FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate CREATE SQL statement from schema for validation\n",
    "print(pd.io.sql.get_schema(df, name='Amsterdam_april_data', con=engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7f32d",
   "metadata": {},
   "source": [
    "Datatypes is only text. Best to correct it! You may have to convert some datatypes so it is always good to do this check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4273e5a-2d44-4a97-a363-eca057eb507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Qs_in_Avg</th>\n",
       "      <th>T1_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-01 03:41:00</td>\n",
       "      <td>-3.055</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-01 03:42:00</td>\n",
       "      <td>-2.959</td>\n",
       "      <td>8.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-01 03:43:00</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-01 03:44:00</td>\n",
       "      <td>-2.884</td>\n",
       "      <td>8.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-04-01 03:45:00</td>\n",
       "      <td>-2.894</td>\n",
       "      <td>8.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Qs_in_Avg  T1_Avg\n",
       "1 2024-04-01 03:41:00     -3.055    8.40\n",
       "2 2024-04-01 03:42:00     -2.959    8.39\n",
       "3 2024-04-01 03:43:00     -3.439    8.38\n",
       "4 2024-04-01 03:44:00     -2.884    8.37\n",
       "5 2024-04-01 03:45:00     -2.894    8.37"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a751ed",
   "metadata": {},
   "source": [
    "## Finally inserting data\n",
    "\n",
    "There are 42980 rows in our dataset. We can use  ```iter_batches()``` function to create batches of 100,000, convert them into pandas and then load it into the postgres database.\n",
    "\n",
    "\n",
    "But we have small dataset here, so we can load it in one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "041e4190-550a-4436-9e28-eb3c1a6e5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Creating just the table in postgres\n",
    "df.to_sql(name='Amsterdam_april_data',con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e20cec73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:49:28.768786Z",
     "start_time": "2023-12-03T23:49:28.689732Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #This part is for testing\n",
    "# # Creating batches of 100,000 for the paraquet file\n",
    "# batches_iter = file.iter_batches(batch_size=100000)\n",
    "# batches_iter\n",
    "\n",
    "# # Take the first batch for testing\n",
    "# df = next(batches_iter).to_pandas()\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fdda025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T00:08:07.651559Z",
     "start_time": "2023-12-04T00:02:35.940526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting batch 1...\n",
      "inserted! time taken     10.121 seconds.\n",
      "\n",
      "inserting batch 2...\n",
      "inserted! time taken      9.521 seconds.\n",
      "\n",
      "inserting batch 3...\n",
      "inserted! time taken      9.797 seconds.\n",
      "\n",
      "inserting batch 4...\n",
      "inserted! time taken     11.570 seconds.\n",
      "\n",
      "inserting batch 5...\n",
      "inserted! time taken     13.581 seconds.\n",
      "\n",
      "inserting batch 6...\n",
      "inserted! time taken     10.042 seconds.\n",
      "\n",
      "inserting batch 7...\n",
      "inserted! time taken     10.305 seconds.\n",
      "\n",
      "inserting batch 8...\n",
      "inserted! time taken     10.392 seconds.\n",
      "\n",
      "inserting batch 9...\n",
      "inserted! time taken     10.364 seconds.\n",
      "\n",
      "inserting batch 10...\n",
      "inserted! time taken      9.715 seconds.\n",
      "\n",
      "inserting batch 11...\n",
      "inserted! time taken      9.843 seconds.\n",
      "\n",
      "inserting batch 12...\n",
      "inserted! time taken      9.540 seconds.\n",
      "\n",
      "inserting batch 13...\n",
      "inserted! time taken      9.815 seconds.\n",
      "\n",
      "inserting batch 14...\n",
      "inserted! time taken      9.740 seconds.\n",
      "\n",
      "inserting batch 15...\n",
      "inserted! time taken     10.005 seconds.\n",
      "\n",
      "inserting batch 16...\n",
      "inserted! time taken      9.581 seconds.\n",
      "\n",
      "inserting batch 17...\n",
      "inserted! time taken     10.054 seconds.\n",
      "\n",
      "inserting batch 18...\n",
      "inserted! time taken     10.518 seconds.\n",
      "\n",
      "inserting batch 19...\n",
      "inserted! time taken     12.060 seconds.\n",
      "\n",
      "inserting batch 20...\n",
      "inserted! time taken     10.032 seconds.\n",
      "\n",
      "inserting batch 21...\n",
      "inserted! time taken      9.673 seconds.\n",
      "\n",
      "inserting batch 22...\n",
      "inserted! time taken     10.380 seconds.\n",
      "\n",
      "inserting batch 23...\n",
      "inserted! time taken      9.967 seconds.\n",
      "\n",
      "inserting batch 24...\n",
      "inserted! time taken     10.053 seconds.\n",
      "\n",
      "inserting batch 25...\n",
      "inserted! time taken     10.252 seconds.\n",
      "\n",
      "inserting batch 26...\n",
      "inserted! time taken     11.429 seconds.\n",
      "\n",
      "inserting batch 27...\n",
      "inserted! time taken     10.368 seconds.\n",
      "\n",
      "inserting batch 28...\n",
      "inserted! time taken     10.074 seconds.\n",
      "\n",
      "inserting batch 29...\n",
      "inserted! time taken     10.679 seconds.\n",
      "\n",
      "inserting batch 30...\n",
      "inserted! time taken      6.672 seconds.\n",
      "\n",
      "Completed! Total time taken was    306.661 seconds for 30 batches.\n"
     ]
    }
   ],
   "source": [
    "# # Insert values into the table \n",
    "# t_start = time()\n",
    "# count = 0\n",
    "# for batch in file.iter_batches(batch_size=100000):\n",
    "#     count+=1\n",
    "#     batch_df = batch.to_pandas()\n",
    "#     print(f'inserting batch {count}...')\n",
    "#     b_start = time()\n",
    "    \n",
    "#     batch_df.to_sql(name='ny_taxi_data',con=engine, if_exists='append')\n",
    "#     b_end = time()\n",
    "#     print(f'inserted! time taken {b_end-b_start:10.3f} seconds.\\n')\n",
    "    \n",
    "# t_end = time()   \n",
    "# print(f'Completed! Total time taken was {t_end-t_start:10.3f} seconds for {count} batches.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c102be",
   "metadata": {},
   "source": [
    "## Extra bit\n",
    "\n",
    "While trying to do the SQL Refresher, there was a need to add a lookup zones table but the file is in ```.csv``` format. \n",
    "\n",
    "Let's code to handle both ```.csv``` and ```.paraquet``` files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643d171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T20:59:29.236458Z",
     "start_time": "2023-12-05T20:59:28.551221Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd \n",
    "import pyarrow.parquet as pq\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9040a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T21:18:11.346552Z",
     "start_time": "2023-12-05T21:18:11.337475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yellow_tripdata_2023-09.parquet'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv'\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet'\n",
    "\n",
    "file_name = url.rsplit('/', 1)[-1].strip()\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495fa96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T21:18:33.001561Z",
     "start_time": "2023-12-05T21:18:32.844872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh yea\n"
     ]
    }
   ],
   "source": [
    "if '.csv' in file_name:\n",
    "    print('yay') \n",
    "    df = pd.read_csv(file_name, nrows=10)\n",
    "    df_iter = pd.read_csv(file_name, iterator=True, chunksize=100000)\n",
    "elif '.parquet' in file_name:\n",
    "    print('oh yea')\n",
    "    file = pq.ParquetFile(file_name)\n",
    "    df = next(file.iter_batches(batch_size=10)).to_pandas()\n",
    "    df_iter = file.iter_batches(batch_size=100000)\n",
    "else: \n",
    "    print('Error. Only .csv or .parquet files allowed.')\n",
    "    sys.exit() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556748f",
   "metadata": {},
   "source": [
    "This code is a rough code and seems to be working. The cleaned up version will be in `data-loading-parquet.py` file."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
